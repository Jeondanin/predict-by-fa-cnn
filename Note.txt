Below Content from MDPI article "Stock price movement prediction Based on a Deep Factorization Machine and the Attention Mechanism"
And This is just memo for reading



3.2. Model Design

3.2.1. Overall Structure of FA-CNN Model
In this section, we introduce our proposed FA-CNN hybrid model in detail. The
overall structure of the model is shown in Figure 1. The feature extraction part of the model
can be divided into two independent modules: (1) the DeepFM module, for automatically
extracting intraday feature interactions, as detailed in Section 3.2.2; and (2) the ATTCNN module, for extracting multiday temporal features, as detailed in Section 3.2.3. The
outputs of these two modules are concatenated and fed to the last full connection layer
for classification. In order to explain the model prediction process more clearly, Figure 2
was drawn to show how the model get the prediction results step by step. Combined with
Figure 1, the proposed FA-CNN hybrid model can be easily understood.

3.2.1. 전체적인 FA-CNN 모델의 구조
이 섹션에서는, 우리가 제안한 FA-CNN하이브리드 모델의 상세한 내용을 설명한다.
모델의 전체적인 구조는 그림 1과 같다. 모델의 특징추출 부분은 2가지 독립한 모듈로 나뉜다.
(1) DeepFm 모듈 - 자동적으로 하루 중의 특징 상호작용을 추출하는 역할이며 3.2.2에서 언급하겠다.
(2) ATT-CNN 모듈  - 여러날읠 시간적 특징을 추출하는 역할이며 3.2.3에서 언급하겠다.
이 2개의 각각의 모듈의 결과를 결합(concatenated)하고 마지막 풀커넥션 레이어에 분류화로 넘긴다. 
더 깔끔하게 모델 예측 과정을 설명하기 위해서 그림 2에서 모델이 단계적으로 예측결과를 얻는 지를 
알려주고 있다. 그림1과 결합하면 제안하는 FA-CNN 하이브리드 모델이 쉽게 이해될 것이다.

3.2.2. DeepFM Module
DeepFM [11] consists of two layers—the FM layer and the deep layer—that share the
same input. The FM layer extracts the low-order (order-1 and order-2) feature interactions
of the input data to get FFM. The deep layer extracts the high-order feature interactions to
get FDNN. These two outputs are then added and activated to obtain Fe as the output of the
DeepFM module, as shown in Equation (5):
Fe = sigmoid(FFM + FDNN) (5)
The advantage of DeepFM is that it can learn the feature interactions of different
orders without feature engineering. Its detailed calculation process is shown in Figure 3.

3.2.2 DeepFM 모듈
DeepFM [11] 은 2개의 FM레이어와 같은 인풋을 공유하는deep레이어로 이루어져 있다.
FM 레이어는 FFM을 얻기 위해 인풋 데이터의 low-order(order-1 과 order-2)특징의 상호작용을  추출한다. 
deep 레이어는 FDNN을 얻기 위해 high-order특징의 상호작용을 추출한다. 
이러한 2개의 결과는 DeepFM모듈의 아웃풋인 Fe가 나와야 하기 때문에 그 후 더해지고 활성화된다. 
아래에 방정식 5에 나타난다.
Fe = sigmoid(FFM + FDNN) (5)
DeepFM의 장점은 feature engineerring 없이 다른 순서간의 특징의 상호작용을 학습할 수 있다. 
이러한 자세한 계산 과정은 그림 3에 표시했다.


The DNN part learns the high-order feature interactions and takes the Embedding
generated by the FM part as the input. The Embedding is also denoted as a0 in Equation (9).
The output of the lth hidden layer in the DNN is denoted as a
l+1
in Equation (10), where
Wl and b
l are the parameters. The final output, FDNN, is defined as Equation (11), where H
is the number of hidden layers:

DNN 부분은 high-order 특징의 상호작용을 배우고 인풋으로서 FM에서 만들어진 Embedding을 취한다.
이러한 Embedding은 방정식 9에 표시한다. 
Dnn의 l번째 레이어의 아웃풋은 방정식 10에 표시한다.
wl, bl은 파라미터이다.
최종 아웃풋 FDNN은 방정식 11에 의해 나타내지고 H는 히든레이어의 갯수이다.



3.2.3. ATT-CNN Module
In this paper, we modify the original CBAM module [46] to enhance the ability of the
CNN to recognize the important points in the time series data. The overall structure of the
ATT-CNN module is shown in Figure 4.
The ith row vector of input matrix xi(t) (denoted as X in Figure 4) represents the stock
state at time i. Intuitively, the state near the current time or the state with obvious trend
change may have a greater impact on stock price movement at the current time. Therefore,
the spatial attention module is used to calculate the weight for each time point. The
adjusted X
0
is then fed into a CNN for temporal feature pattern extraction. The row vector
is an indivisible unit due to its representation of the stock state. Thus, the size of filters
is set to be l × w, where l is the length of the time window and w is the dimension of the
row vector in the input matrix. Many feature maps are obtained using different filters after
convolutional operation, but not every feature map is of the same importance. Therefore,
the channel attention module is used to calculate the weight for each feature map. The
matrix P
0
, adjusted by the channel attention map and spatial attention map, is finally fed to
another CNN to get the output. The concise expression of the above calculation process is
shown in Equations (12)–(15):
3.2.3 ATT-CNN Module

이 논문에서는, 우리는 시계열 데이터의 중요한 포인트를 인지하기 위한 CNN의 능력을 강화하기 위해 CMAB 모듈의 원형을 수정했다.
전체적인 ATT-CNN 모듈의 구조는 아래 그림4와 같다.
인풋 행렬 xi(t)의 i번째 행 벡터는 시각 i의 stock stock을 나타낸다. 직감적으로 현재 시각의 근처 상태 또는 
명확한 추이 변화의 상태는 현재시각의 주가 가격 움직임에 더 큰 영향을 줄 것이다. 그러므로
각 시각의 점수에 관한 계수를 계산하는 데에 공간 집중 모듈(the spaial attention module)은 사용된다.
그렇게 조정된 X'은 시간적 특징 패턴 추출을 위해 CNN에 넘어간다.
주가상태 자체를 나타내고 있기 떄문에  행 벡터는 나눌 수 없는 단위이다. 
그러므로 필터의 크기는 l*w가 되어야 하며, 이 때 l은 시간 window의 길이이고 w는 행 벡터의 차수이다.
콘볼루션 연산 후 많은 특징 맵은 다른 필터를 사용하면서 얻어지지만, 모든 피쳐맵이 같은 중요도를 갖지 않는다.
그렇기 때문에 채널 집중 모듈은 각 특징맵의 계수를 계산하기 위해 사용된다. 
행렬 P'는 채널집중맵과 공간집중맵에 의해 조정되었기 때문에, 최종적으로 다른 CNN으로 넘어가며 
아웃풋을 얻어낸다. 위의 계산과정을 간략히 나타내면 아래 방정식 12-15가 된다.

Spatial Attention in ATT-CNN Module
As shown in Figure 5, the spatial attention map focuses on telling the network which
row of input matrix X carries more important information. It performs average pooling and
max pooling for each position in input matrix X channel-dimensionally. After the pooling
operation, the results are stacked and fed into the CNN with a 1 × w filter size, where w is
the dimension of the row vector in the input matrix. As such, the model treats the stock
state vector as a whole instead of as the original filter size of 7 × 7. Finally, the result is
activated by sigmoid function to make the elements in Ms range from 0 to 1, representing
the importance of the corresponding time point. The calculation process of Ms
is shown in
Equation (16):
Ms = σ

ATT-CNN 모듈에서의 공간 집중 
그림 5에서와 같이 공간 집중 맵은 더욱 중요한 정보를 가지고 있는 인풋 매트릭스 x에 포함된 행을 구별하는데
초점이 맞춰진 것이다. 이것은 average pooling과 max pooling이 채널 차원적으로 인풋 행렬 X의 각 위치에서
수행한다. pooling 연산이 끝나고, 그 결과들은 stacked되고 1*w의 크기를 갖는 CNN 필터 사이즈로 넘어간다.
이러게 하면 모델은 stock state 벡터를 7*7 사이즈의 원형 필터 사이즈 대신해 전체로서 다루고 있다.
결국, 결과는 시그모이드 함수에 의해 activated되고  이것은 0과 1사이의 범위를 갖기 위한 것이고
시간 점수 상응의 중요도를 의미한다. 다음 과정은 Ms  아래 방정식 16 이다.

Channel Attention in ATT-CNN Module
As shown in Figure 6, the channel attention map focuses on telling the network which
feature map carries more important information. In contrast to the spatial attention module,
this module uses global average pooling and global max pooling to compress each feature
map into vectors Fc avg and Fc max, respectively, with the same size of C × 1 × 1, where C is
the number of channels. Vectors Fc avg and Fc max can be regarded as the intuitive interpreter
of each feature map. Both vectors are fed to a shared two-layer fully connected neural
network to obtain the nonlinear maps. Finally, these two maps are added and activated by
sigmoid function to make sure each element in Mc is between 0 and 1, which represents
the importance of the corresponding channel. The calculation process of Mc is shown in

ATT-CNN 모듈에서의 채널 집중
그림 6에서와 같이, 채널 집중맵은 공간집중맵과 같은 역할을 하지만, 이 모듈은 
글로벌 average pooling과 글로벌 max pooling을 
사이즈가 C * 1 * 1 로 같은 벡터 Fc average와 벡터 Fc global로 각각 압축 된다. 
C는 여기서 채널 수를 의미한다. 그것들은 각 특징맵의 직감적 해석기로 여길 수 있다.
두 백터는 nonlinear 맵을 얻기 위해 공유되는 2층 fully connected neural network로 넘어간다. 
결과적으로 2개의 맵은 더해지고 시그모이드에 의해 activated되는데 Mc에 있는 0과 1사이의 각 엘리먼트를 
확실히 하기 위해. 채널에 대응하는 중요도를 의미한다. 식은 17과 같다.








